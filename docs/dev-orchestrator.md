# EcoHub Dev Orchestrator ‚Äì Complete Guide

## Overview

The **Dev Orchestrator** is an automated system that:

1. ‚úÖ **Verifies Supabase connectivity** and captures DB health metrics
2. ‚úÖ **Runs build health checks** (lint, TypeScript, build)
3. ‚úÖ **Checks MCP server status** (mcp-context-server, ecohub-qa)
4. ‚úÖ **Generates multi-model prompt bundles** for Claude, ChatGPT, Gemini, Grok, and Codex CLI
5. ‚úÖ **Logs all outputs** to `mcp-outputs/` for reference

## Quick Start

### Run the Orchestrator

```bash
pnpm dev:orchestrator
```

This command:

- Takes ~10-15 seconds (build checks are the slowest part)
- Writes logs to `mcp-outputs/` (JSON format)
- Generates 5 model-specific prompts in `prompts/`
- Prints a summary to console

### Use the Generated Prompts

1. **For Claude Sonnet/Haiku:**

   ```bash
   cat prompts/bootstrap.claude.md
   # Copy entire contents and paste into Claude conversation
   ```

2. **For ChatGPT GPT-5.1:**

   ```bash
   cat prompts/bootstrap.chatgpt.md
   # Paste into ChatGPT before asking your task
   ```

3. **For Gemini 3.0 Pro:**

   ```bash
   cat prompts/bootstrap.gemini.md
   ```

4. **For Grok:**

   ```bash
   cat prompts/bootstrap.grok.md
   ```

5. **For Codex CLI:**
   ```bash
   cat prompts/bootstrap.codex-cli.md
   # Reference when using: codex --prompt ...
   ```

## Output Structure

### Logs Directory: `mcp-outputs/`

After running `pnpm dev:orchestrator`, you'll see:

```
mcp-outputs/
‚îú‚îÄ‚îÄ db_check.log           # Supabase connectivity + eco_listings count
‚îú‚îÄ‚îÄ mcp_status.log         # MCP server process status
‚îî‚îÄ‚îÄ build_health.log       # Lint, TypeScript, build results (JSON)
```

**Example `db_check.log`:**

```json
{
  "status": "Supabase Connectivity Check",
  "reachable": true,
  "ecoListingsCount": 142,
  "ecoOrganizationsCount": 18,
  "timestamp": "2025-11-23T14:35:22Z"
}
```

### Prompts Directory: `prompts/`

5 model-specific bootstraps:

- `bootstrap.claude.md` ‚Äì Optimized for Claude (includes MCP tool instructions)
- `bootstrap.chatgpt.md` ‚Äì Optimized for ChatGPT (includes GPT-5.1 thinking tips)
- `bootstrap.gemini.md` ‚Äì Optimized for Gemini (no MCP tools, relies on logs)
- `bootstrap.grok.md` ‚Äì Optimized for Grok (no MCP tools)
- `bootstrap.codex-cli.md` ‚Äì Optimized for Codex CLI (code-focused, instructions for file pasting)

## Architecture of the Orchestrator

### Main Components

**File: `scripts/dev-orchestrator.ts`** (TypeScript, ~400 lines)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  pnpm dev:orchestrator (tsx scripts/dev-orchestrator.ts)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îú‚îÄ Step 1: Check Supabase Connectivity
           ‚îÇ          ‚îî‚îÄ Run: SELECT COUNT(*) FROM eco_listings
           ‚îÇ          ‚îî‚îÄ Write: mcp-outputs/db_check.log
           ‚îÇ
           ‚îú‚îÄ Step 2: Check MCP Servers
           ‚îÇ          ‚îî‚îÄ Check: ps aux for mcp-context-server, ecohub-qa
           ‚îÇ          ‚îî‚îÄ Write: mcp-outputs/mcp_status.log
           ‚îÇ
           ‚îú‚îÄ Step 3: Run Build Health Checks
           ‚îÇ          ‚îú‚îÄ pnpm lint
           ‚îÇ          ‚îú‚îÄ pnpm tsc --noEmit
           ‚îÇ          ‚îî‚îÄ pnpm build (sample last 20 lines)
           ‚îÇ          ‚îî‚îÄ Write: mcp-outputs/build_health.log
           ‚îÇ
           ‚îú‚îÄ Step 4: Read Core Documentation
           ‚îÇ          ‚îú‚îÄ docs/dev-bootstrap-prompts.md
           ‚îÇ          ‚îú‚îÄ docs/supabase-connection.md
           ‚îÇ          ‚îú‚îÄ docs/architecture-plan.md
           ‚îÇ          ‚îú‚îÄ docs/data-layer-review.md
           ‚îÇ          ‚îî‚îÄ docs/marketplace-v2-tutorial-sq.md
           ‚îÇ
           ‚îú‚îÄ Step 5: Generate Root Bootstrap Template
           ‚îÇ          ‚îî‚îÄ Merges logs + docs into unified context
           ‚îÇ
           ‚îî‚îÄ Step 6: Generate 5 Model-Specific Prompts
                      ‚îú‚îÄ bootstrap.claude.md
                      ‚îú‚îÄ bootstrap.chatgpt.md
                      ‚îú‚îÄ bootstrap.gemini.md
                      ‚îú‚îÄ bootstrap.grok.md
                      ‚îî‚îÄ bootstrap.codex-cli.md
```

## Troubleshooting

### "Supabase not reachable"

**Cause:** `SUPABASE_DB_URL` environment variable not set or points to wrong host.

**Fix:**

```bash
# Verify env var
echo $SUPABASE_DB_URL

# Should output something like:
# postgresql://postgres:[password]@aws-1-eu-west-1.pooler.supabase.com:6543/postgres

# If missing, source your .env.local
source .env.local
pnpm dev:orchestrator
```

### "MCP servers not detected"

**Cause:** `mcp-context-server` or `ecohub-qa-server` not running.

**Fix:**

```bash
# Start them
pnpm dev

# In another terminal, run the orchestrator
pnpm dev:orchestrator
```

### "Build/Lint/TypeScript checks failed"

**Cause:** Code has errors.

**Fix:**

```bash
# Check local errors
pnpm lint
pnpm tsc --noEmit
pnpm build

# Fix errors
# Then re-run orchestrator
pnpm dev:orchestrator
```

### "Prompts not generated"

**Cause:** Missing documentation files in `docs/`.

**Fix:**

```bash
# Verify required docs exist
ls docs/dev-bootstrap-prompts.md
ls docs/supabase-connection.md
ls docs/architecture-plan.md

# If missing, the orchestrator will still generate prompts but with incomplete info
# Re-run after files are added
pnpm dev:orchestrator
```

## When to Re-Run the Orchestrator

**Run BEFORE each AI model session:**

```bash
pnpm dev:orchestrator
```

You should re-run if:

- ‚úÖ You made significant code changes
- ‚úÖ You switched between branches
- ‚úÖ Build health changed
- ‚úÖ DB schema was migrated
- ‚úÖ Starting a fresh AI session
- ‚úÖ You forgot the current context

**Why?** The orchestrator guarantees your AI model has:

- Current architecture snapshot
- Real build/lint status
- Live Supabase connection metrics
- Fresh MCP server availability

## Integration with AI Workflows

### Claude + MCP Tools Workflow

1. Run orchestrator:

   ```bash
   pnpm dev:orchestrator
   ```

2. Paste `prompts/bootstrap.claude.md` into Claude

3. Give Claude a task, e.g.:

   > "Fix the marketplace location filter to use Kosovo cities"

4. Claude will:
   - Use `project_map` to see repo structure
   - Use `code_search` to find relevant files
   - Use `read_files` to inspect actual code
   - Propose changes based on real code
   - Ask you to run `pnpm lint && pnpm build` to validate

### ChatGPT + Tools Workflow

1. Run orchestrator:

   ```bash
   pnpm dev:orchestrator
   ```

2. Paste `prompts/bootstrap.chatgpt.md` into ChatGPT

3. Tell ChatGPT your task

4. ChatGPT can use available tools (Code Interpreter, Web Browsing) for context

### Gemini/Grok/Codex CLI Workflow (No MCP)

1. Run orchestrator:

   ```bash
   pnpm dev:orchestrator
   ```

2. Paste `prompts/bootstrap.gemini.md` (or grok/codex) into your model

3. If model asks for specific files:
   - Request via `code_search`: "Search for files related to marketplace listings"
   - Provide via `read_files`: "Show me src/services/listings.ts"
   - Use logs from `mcp-outputs/` to answer status questions

## Advanced: Custom Orchestrator Runs

### Quick DB Status Check Only

```bash
# From Node.js REPL or custom script
SUPABASE_DB_URL=$(echo $SUPABASE_DB_URL) pnpm dlx ts-node -e "
  import { execSync } from 'child_process';
  const out = execSync('psql \"\$SUPABASE_DB_URL\" -c \"SELECT COUNT(*) FROM eco_listings;\"', { encoding: 'utf-8' });
  console.log(out);
"
```

### Run Just Build Checks

```bash
# Lint + TypeScript + Build
pnpm lint && pnpm tsc --noEmit && pnpm build
```

### Generate Prompts Manually

If you only want prompts without orchestrator overhead:

```bash
# Read a single prompt template
cat prompts/bootstrap.claude.md
```

Or edit `tools/dev-orchestrator.ts` to skip certain steps by commenting out Step 1-3 and just running Step 4-6.

## Expected Output Example

```
[DEV-ORCHESTRATOR] üöÄ EcoHub Dev Orchestrator Starting
[DEV-ORCHESTRATOR] ========================================

[DEV-ORCHESTRATOR] Checking Supabase connectivity...
‚úÖ Supabase reachable (eco_listings: 142, eco_organizations: 18)
‚ÑπÔ∏è  Wrote db_check.log

[DEV-ORCHESTRATOR] Checking MCP servers...
‚úÖ MCP context server running
‚úÖ EcoHub QA server running
‚ÑπÔ∏è  Wrote mcp_status.log

[DEV-ORCHESTRATOR] Running build health checks...
‚úì Compiled successfully in 3.7s
‚úÖ Lint check passed
‚úÖ TypeScript check passed
‚úÖ Build check passed
‚ÑπÔ∏è  Wrote build_health.log

[DEV-ORCHESTRATOR] Reading core documentation...
[DEV-ORCHESTRATOR] Generating multi-model prompt bundles...
‚úÖ Generated bootstrap.claude.md
‚úÖ Generated bootstrap.chatgpt.md
‚úÖ Generated bootstrap.gemini.md
‚úÖ Generated bootstrap.grok.md
‚úÖ Generated bootstrap.codex-cli.md

============================================================
‚úÖ All orchestration steps completed!
============================================================

‚úÖ Supabase Status:
   ‚úÖ Reachable
   eco_listings: 142
   eco_organizations: 18

‚úÖ Build Health:
   Lint: ‚úÖ PASS
   TypeScript: ‚úÖ PASS
   Build: ‚úÖ PASS

============================================================
üìÇ Output Locations:
   Logs: /Users/.../ecohubkosova/mcp-outputs/
   Prompts: /Users/.../ecohubkosova/prompts/

============================================================
üéØ Next Steps:
   1. Open prompts/bootstrap.claude.md and paste into Claude
   2. For ChatGPT: use prompts/bootstrap.chatgpt.md
   3. For Gemini: use prompts/bootstrap.gemini.md
   4. For Grok: use prompts/bootstrap.grok.md
   5. For Codex CLI: use prompts/bootstrap.codex-cli.md

   When in doubt, re-run: pnpm dev:orchestrator
```

## Summary

| Aspect          | Details                                         |
| --------------- | ----------------------------------------------- |
| **Command**     | `pnpm dev:orchestrator`                         |
| **Duration**    | ~10-15 seconds                                  |
| **Output**      | Logs in `mcp-outputs/`, prompts in `prompts/`   |
| **Frequency**   | Before each AI session or after code changes    |
| **Key Benefit** | Guarantees AI model has fresh, accurate context |

---

**Questions?** See `docs/architecture-plan.md` for system design or ask your AI assistant with the generated prompt!
